{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.models import Model, Input\n",
    "from keras.applications import xception\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, Callback\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = '/mlsteam/input'\n",
    "train_folder = os.path.join(base_folder, 'train')\n",
    "test_folder = os.path.join(base_folder, 'test')\n",
    "\n",
    "label_file = os.path.join(base_folder, 'labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.read_csv(label_file)\n",
    "NUM_CLASSES = 20\n",
    "\n",
    "random.seed(NUM_CLASSES)\n",
    "\n",
    "total_breed = list(train_label.groupby('breed').count().sort_values(by='id', ascending=False).index)\n",
    "\n",
    "top_num_breed = list(train_label.groupby('breed').count().sort_values(by='id', ascending=False).head(NUM_CLASSES).index)\n",
    "\n",
    "train_df = pd.DataFrame()\n",
    "valid_df = pd.DataFrame()\n",
    "\n",
    "ratio = 0.8\n",
    "print('{:<20} {:>10} {:>10} {:>10}'.format('Breed', 'Total', 'Train', 'Valid'))\n",
    "print('#'*60)\n",
    "for breed in top_num_breed:\n",
    "    tmp = train_label.loc[train_label['breed'].isin([breed])].reset_index(drop=True)\n",
    "    train_num = int(len(tmp) * 0.8)\n",
    "    print('{:<20} {:10} {:10} {:10}'.format(breed, len(tmp), train_num, len(tmp) - train_num))\n",
    "    \n",
    "    # random\n",
    "    tmp_list = list(range(len(tmp)))\n",
    "    random.shuffle(tmp_list)\n",
    "\n",
    "    train_df = train_df.append(tmp.iloc[tmp_list[:train_num]], ignore_index=True)\n",
    "    valid_df = valid_df.append(tmp.iloc[tmp_list[train_num:]], ignore_index=True)\n",
    "\n",
    "for i, row in train_df.iterrows():\n",
    "    train_df.at[i, 'id'] = row['id'] + '.jpg'\n",
    "\n",
    "for i, row in valid_df.iterrows():\n",
    "    valid_df.at[i, 'id'] = row['id'] + '.jpg'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(train_df)\n",
    "#print(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    #samplewise_center=True,\n",
    "    #samplewise_std_normalization=True,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.25,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "                        dataframe=train_df,\n",
    "                        directory=train_folder,\n",
    "                        x_col=\"id\",\n",
    "                        y_col=\"breed\",\n",
    "                        class_mode=\"categorical\",\n",
    "                        target_size=(299, 299),\n",
    "                        batch_size=32,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_generator = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n",
    "                        dataframe=valid_df,\n",
    "                        directory=train_folder,\n",
    "                        x_col=\"id\",\n",
    "                        y_col=\"breed\",\n",
    "                        class_mode=\"categorical\",\n",
    "                        target_size=(299, 299),\n",
    "                        batch_size=16,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL - BOTTLENECK FEATURES - OPTMIZER\n",
    "\n",
    "\n",
    "\n",
    "# Download and create the pre-trained Xception model for transfer learning\n",
    "base_model = xception.Xception(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = BatchNormalization()(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "# and a logistic layer -- let's say we have NUM_CLASSES classes\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional Xception layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainLogger(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch = epoch\n",
    "    def on_train_batch_end(self, batch, logs={}):\n",
    "        print(\"Train epoch={:.6f} loss={:.6f} acc={:.6f}\".format(self.epoch+batch/self.params.get('steps'), logs.get('loss'), logs.get('accuracy')))\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        print(\"Validation epoch={:.6f} loss={:.6f} acc={:.6f}\".format(epoch+1.0, logs.get('val_loss'), logs.get('val_accuracy')))\n",
    "        \n",
    "tb_callBack = TensorBoard(log_dir='./tb', histogram_freq=0, write_graph=True, write_images=True)\n",
    "model_checkpoint = ModelCheckpoint(filepath='./checkpoints', monitor='loss', verbose=0, save_best_only=True)\n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "                    validation_data=valid_generator,\n",
    "                    verbose=0, \n",
    "                    callbacks=[tb_callBack, model_checkpoint, TrainLogger()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pred = model.predict_generator(valid_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(valid_generator.labels, np.argmax(valid_pred,axis=1))\n",
    "\n",
    "# Mapping\n",
    "breed_mapping = {v: k for k, v in train_generator.class_indices.items()}\n",
    "breed_list = [b for b in breed_mapping.values()]\n",
    "df_cm = pd.DataFrame(cnf_matrix, index=breed_list, columns=breed_list)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "try:\n",
    "    heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "except ValueError:\n",
    "    raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=10)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=10)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgs(path):\n",
    "    imgs = []\n",
    "    for entry in os.scandir(path):\n",
    "        if entry.is_dir():\n",
    "            imgs.extend(get_imgs(entry.path))\n",
    "        else:\n",
    "            imgs.append(entry.path)\n",
    "    return imgs\n",
    "\n",
    "test_imgs = get_imgs(test_folder)\n",
    "\n",
    "test_df = pd.DataFrame({\"x\":test_imgs[:64]})\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n",
    "                        test_df,\n",
    "                        x_col='x',\n",
    "                        class_mode=None,\n",
    "                        target_size=(299, 299),\n",
    "                        batch_size=32,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(test_generator, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first batch\n",
    "test_generator.reset()\n",
    "first_batch = test_generator.next()\n",
    "(first_batch_imgs) = first_batch\n",
    "first_batch_pred = pred[:len(first_batch_imgs)]\n",
    "\n",
    "def get_max_index(array):\n",
    "    max = 0\n",
    "    max_index = 0\n",
    "    for i in range(len(array)):\n",
    "        if array[i] > max:\n",
    "            max = array[i]\n",
    "            max_index = i\n",
    "    return max_index\n",
    "\n",
    "# Mapping\n",
    "breed_mapping = {v: k for k, v in train_generator.class_indices.items()}\n",
    "\n",
    "# Start to Plot\n",
    "\n",
    "fig=plt.figure(figsize=(16, 16))\n",
    "columns = 4\n",
    "rows = 5\n",
    "\n",
    "for i in range(1, columns*rows +1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.tick_params(\n",
    "        bottom=False,\n",
    "        left=False,\n",
    "        labelbottom=False,\n",
    "        labelleft=False\n",
    "    )\n",
    "    plt.tight_layout(pad=2, h_pad=0.2, w_pad=0.2)\n",
    "    plt.title(breed_mapping[get_max_index(first_batch_pred[i-1])])\n",
    "    plt.imshow(first_batch_imgs[i-1])\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('prediction_20.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
